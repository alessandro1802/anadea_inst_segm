{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b409a2633bce8e3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef1effbb4c4c6be6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:26:13.020974Z",
     "start_time": "2024-11-11T19:26:10.767647Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as maskUtils\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torchmetrics\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c6f89fc42c2029",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679af905baec18a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:26:13.025077Z",
     "start_time": "2024-11-11T19:26:13.023405Z"
    }
   },
   "outputs": [],
   "source": [
    "annotation_file = \"./data/LIVECell_dataset_2021/annotations/LIVECell/livecell_coco_train_val.json\"\n",
    "annotation_test_file = \"./data/LIVECell_dataset_2021/annotations/LIVECell/livecell_coco_test.json\"\n",
    "\n",
    "image_dir = \"./data/LIVECell_dataset_2021/images/livecell_train_val_images\"\n",
    "image_test_dir = \"./data/LIVECell_dataset_2021/images/livecell_test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca787969230b51e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:26:13.585558Z",
     "start_time": "2024-11-11T19:26:13.581828Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_filenames = [f for f in os.listdir(image_dir) if f.endswith('.tif')]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf368984401d785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:26:47.638681Z",
     "start_time": "2024-11-11T19:26:14.507716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.5021, 0.5021, 0.5021])\n",
      "Std: tensor([0.0422, 0.0422, 0.0422])\n"
     ]
    }
   ],
   "source": [
    "# Define a dataset and loader without transformations\n",
    "dataset = CustomImageDataset(image_dir=image_dir, transform=transforms.ToTensor())\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Initialize running means and standard deviations\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "num_samples = 0\n",
    "\n",
    "for images in loader:\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)  # Flatten H and W\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    num_samples += batch_samples\n",
    "\n",
    "mean /= num_samples\n",
    "std /= num_samples\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dacb8ca07b86a9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:26:47.649148Z",
     "start_time": "2024-11-11T19:26:47.647480Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bac69a647430161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:26:47.658336Z",
     "start_time": "2024-11-11T19:26:47.654796Z"
    }
   },
   "outputs": [],
   "source": [
    "models_path = \"./models\"\n",
    "transform_path = os.path.join(models_path, \"transform.pkl\")\n",
    "\n",
    "with open(transform_path, 'wb') as f:\n",
    "    pickle.dump(transform, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d37b63a219b23",
   "metadata": {},
   "source": [
    "# Data-loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6c6e7230740ed72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:26:47.670610Z",
     "start_time": "2024-11-11T19:26:47.664032Z"
    }
   },
   "outputs": [],
   "source": [
    "class LIVECellDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, annotation_file, annotation_test_file, image_test_dir, image_dir, batch_size=4, transform=None, val_split=0.2):\n",
    "        super().__init__()\n",
    "        self.annotation_file = annotation_file\n",
    "        self.annotation_test_file = annotation_test_file\n",
    "        self.image_dir = image_dir\n",
    "        self.image_test_dir = image_test_dir\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        self.val_split = val_split\n",
    "            \n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            with open(os.devnull, 'w') as fnull:\n",
    "                with redirect_stdout(fnull):\n",
    "                    coco = COCO(self.annotation_file)\n",
    "            all_image_ids = coco.getImgIds()\n",
    "    \n",
    "            np.random.seed(123)\n",
    "            np.random.shuffle(all_image_ids)\n",
    "            num_val = int(len(all_image_ids) * self.val_split)\n",
    "    \n",
    "            train_image_ids = all_image_ids[num_val:]\n",
    "            val_image_ids = all_image_ids[:num_val]\n",
    "        \n",
    "            self.train_dataset = LIVECellDataset(coco, self.image_dir, image_ids=train_image_ids, transform=self.transform)\n",
    "            self.val_dataset = LIVECellDataset(coco, self.image_dir, image_ids=val_image_ids, transform=self.transform)\n",
    "        elif stage == 'test':\n",
    "            with open(os.devnull, 'w') as fnull:\n",
    "                with redirect_stdout(fnull):\n",
    "                    coco_test = COCO(self.annotation_test_file)\n",
    "                all_image_ids = coco_test.getImgIds()\n",
    "            self.test_dataset = LIVECellDataset(coco_test, self.image_test_dir, image_ids=all_image_ids, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.collate_fn)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, collate_fn=self.collate_fn)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "class LIVECellDataset(Dataset):\n",
    "    def __init__(self, coco, image_dir, image_ids=None, transform=None):\n",
    "        self.coco = coco\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        # Use provided image IDs or all if not provided\n",
    "        self.image_ids = image_ids if image_ids is not None else self.coco.getImgIds()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        image_path = os.path.join(self.image_dir, image_info['file_name'])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        annotation_ids = self.coco.getAnnIds(imgIds=image_id)\n",
    "        annotations = self.coco.loadAnns(annotation_ids)\n",
    "        \n",
    "        mask = np.zeros((image_info['height'], image_info['width']), dtype=np.uint8)\n",
    "        for ann in annotations:\n",
    "            # Decode the binary mask from RLE\n",
    "            rle_mask = self.coco.annToRLE(ann)\n",
    "            binary_mask = maskUtils.decode(rle_mask)\n",
    "            mask[binary_mask == 1] = ann['category_id']\n",
    "        mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
    "        # One-hot encode the mask to have a probability distribution at every pixel\n",
    "        one_hot_mask = torch.zeros((2, mask.size(0), mask.size(1)), dtype=torch.float32)        \n",
    "        one_hot_mask[0, :, :] = (mask == 0).float()\n",
    "        one_hot_mask[1, :, :] = (mask == 1).float()\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, one_hot_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a69039acf5b098",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d63bc7e19fe9959f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:27:02.129178Z",
     "start_time": "2024-11-11T19:26:47.676880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Width = 704, Height = 520\n",
      "Image batch shape: torch.Size([4, 3, 520, 704])\n",
      "Mask batch shape: torch.Size([4, 2, 520, 704])\n"
     ]
    }
   ],
   "source": [
    "data_module = LIVECellDataModule(\n",
    "    annotation_file=annotation_file, annotation_test_file=annotation_test_file, \n",
    "    image_dir=image_dir, image_test_dir=image_test_dir, \n",
    "    batch_size=4, transform=transform\n",
    ")\n",
    "data_module.setup(stage='fit')\n",
    "dataloader = data_module.train_dataloader()\n",
    "\n",
    "for images, targets in dataloader:\n",
    "    images = torch.stack(images)\n",
    "    targets = torch.stack(targets)\n",
    "    HEIGHT, WIDTH = images[0].shape[1:]\n",
    "    print()\n",
    "    print(f\"Width = {WIDTH}, Height = {HEIGHT}\")\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Mask batch shape:\", targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259c4e85b4ca4c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d61b3730e62ae0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:27:02.384338Z",
     "start_time": "2024-11-11T19:27:02.379480Z"
    }
   },
   "outputs": [],
   "source": [
    "from model import SegmentationModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3350a7949c8496",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eee23b916145c4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:27:02.394796Z",
     "start_time": "2024-11-11T19:27:02.391704Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "N_CLASSES = 2  # cell vs. background\n",
    "\n",
    "checkpoint_path = os.path.join(models_path, \"checkpoints\")\n",
    "checkpoint_filename = \"MobileNetV2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cb84ea6cc1e386a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:27:02.409970Z",
     "start_time": "2024-11-11T19:27:02.404498Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    min_delta=0.01, \n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    save_top_k=1,\n",
    "    mode='min',\n",
    "    dirpath=checkpoint_path,\n",
    "    filename=checkpoint_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a472852154d14b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:17:23.210849Z",
     "start_time": "2024-11-11T18:56:45.707554Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /home/pcss/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "100%|█████████████████████████████████████████████████| 13.6M/13.6M [00:00<00:00, 19.1MB/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/pcss/Downloads/anadea_inst_segm/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/home/pcss/Downloads/anadea_inst_segm/.venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/pcss/Downloads/anadea_inst_segm/models/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | backbone   | Sequential         | 2.2 M  | train\n",
      "1 | conv1      | Conv2d             | 5.9 M  | train\n",
      "2 | relu       | ReLU               | 0      | train\n",
      "3 | conv2      | Conv2d             | 1.0 K  | train\n",
      "4 | iou_metric | BinaryJaccardIndex | 0      | train\n",
      "----------------------------------------------------------\n",
      "5.9 M     Trainable params\n",
      "2.2 M     Non-trainable params\n",
      "8.1 M     Total params\n",
      "32.495    Total estimated model params size (MB)\n",
      "213       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                   | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcss/Downloads/anadea_inst_segm/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/pcss/Downloads/anadea_inst_segm/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e053efe7ead4c4dbe82d2242ef41fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.323. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "model = SegmentationModule(batch_size=BATCH_SIZE, num_classes=N_CLASSES, height=HEIGHT, width=WIDTH)\n",
    "# Save the model object\n",
    "model_path = os.path.join(models_path, checkpoint_filename) + \".pkl\"\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    devices=1,\n",
    "    accelerator=\"cuda\",\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    check_val_every_n_epoch=1\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a903d92e8de9d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df009edf42749992",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:33:21.252288Z",
     "start_time": "2024-11-11T19:32:10.172434Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/pcss/Downloads/anadea_inst_segm/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57c41b839a04a8ea213e85b22e57300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                           | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_loss_epoch        0.3248176574707031\n",
      "         val_IoU            0.5862681269645691\n",
      "         val_MaP                    0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.3248176574707031,\n",
       "  'val_IoU': 0.5862681269645691,\n",
       "  'val_MaP': 0.0}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module.setup(stage='test')\n",
    "dataloader = data_module.test_dataloader()\n",
    "\n",
    "trainer.test(model=model, dataloaders=dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
